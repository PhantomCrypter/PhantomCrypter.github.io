<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Proyecto | Crawler</title>
  <link rel="stylesheet" href="../assets/css/style.css" />
  <link href="https://fonts.googleapis.com/css2?family=Fira+Code&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
</head>
<body class="glitch-bg">
  <nav class="navbar">
    <ul class="nav-list">
      <li><a href="../index.html">Inicio</a></li>
      <li><a href="../projects.html">Proyectos</a></li>
      <li><a href="../blog.html">Blog</a></li>
      <li><a href="../writeups.html">Writeups</a></li>
      <li><a href="../about.html">Sobre m칤</a></li>
      <li><a href="../contact.html">Contacto</a></li>
    </ul>
  </nav>

  <main class="blog-container">
    <section class="blog-post">
      <div class="terminal-box">
        <a href="../projects.html" class="back-link">&larr; Volver a los proyectos</a>
        <h1></h1>
        <h1 class="post-title">Crawler en P치gina Est치tica</h1>
        <img src="../assets/img/spider.png" alt="Logo de Crawler" class="post-image">
        <article>
            <br>
            <p>
                En este proyecto, me aventur칠 en el fascinante mundo del <strong>web scraping</strong> utilizando <strong>Python</strong> y 
                <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">Beautiful Soup</a>. El objetivo principal fue extraer 
                informaci칩n de una p치gina web est치tica de manera automatizada, lo que me permiti칩 recopilar datos relevantes para su posterior an치lisis o uso.
            </p>

            <p>
                Al emplear Python como lenguaje de programaci칩n principal y Beautiful Soup como biblioteca de an치lisis HTML, pude desarrollar un crawler eficiente y poderoso. 
                El proceso implicaba navegar por el c칩digo HTML de la p치gina objetivo, identificar y extraer los elementos deseados, como texto, enlaces o im치genes, y luego 
                procesar esa informaci칩n seg칰n mis necesidades espec칤ficas.
            </p>

            <p>
                Este proyecto no solo me proporcion칩 una s칩lida comprensi칩n de la manipulaci칩n de datos web con Python, sino que tambi칠n me permiti칩 explorar conceptos como la 
                estructura del documento HTML, la selecci칩n de elementos mediante selectores y la gesti칩n de datos extra칤dos.
            </p>

            <p>
                A lo largo de esta breve introducci칩n, compartir칠 mi experiencia, los desaf칤os enfrentados y las soluciones implementadas durante el desarrollo de este emocionante 
                proyecto de crawler en Python.
            </p>
            <br>

            <h2>游 쯈u칠 es un Crawler?</h2>
            <p>
                Un <strong>crawler</strong>, tambi칠n conocido como "rastreador web" o "ara침a web", es un programa de software que navega por la web de manera automatizada, siguiendo enlaces de 
                una p치gina a otra. Su objetivo principal es <strong>indexar</strong> y  <strong>recopilar</strong> informaci칩n de diversas p치ginas web para su posterior an치lisis o indexaci칩n en motores de 
                b칰squeda. Los crawlers son fundamentales para la indexaci칩n y la recuperaci칩n de informaci칩n en la web, ya que facilitan la recopilaci칩n de datos de manera eficiente 
                y sistem치tica.
            </p>
            <br>

            <h2>丘멆잺 Desventajas de los crawlers</h2>

            <p>
                Los crawlers enfrentan algunas desventajas al tratar con p치ginas que no son est치ticas:
            </p>
            <br>
            <ul>
                <li><h4>Dificultad para rastrear cambios din치micos:</h4> </li>
                    <p>
                        Los crawlers pueden tener dificultades para detectar cambios en el contenido de las p치ginas din치micas, ya que estas se generan mediante scripts o consultas a bases de datos en tiempo 
                        real. Esto significa que los cambios en el contenido pueden no ser capturados de manera oportuna o precisa.
                    </p>
                <li><h4>Posibilidad de rastrear informaci칩n irrelevante o duplicada:</h4></li>
                    <p>
                        Debido a la naturaleza din치mica del contenido, los crawlers pueden encontrarse con dificultades para distinguir entre contenido relevante y contenido redundante o irrelevante que se 
                        genera din치micamente. Esto puede resultar en la indexaci칩n de informaci칩n duplicada o poco 칰til.
                    </p>
                <li><h4>Necesidad de actualizaci칩n constante:</h4></li>
                    <p>
                        Los crawlers deben adaptarse continuamente a los cambios en la estructura y el comportamiento de las p치ginas din치micas para garantizar un rastreo efectivo. Esto puede requerir una 
                        inversi칩n adicional en desarrollo y mantenimiento de software para mantener el crawler actualizado.
                    </p>
            </ul>
<br>
            <p>
                Por esta raz칩n, para este proyecto he decidido utilizar una p치gina web est치tica para as칤 asegurar que este proyecto sea 100% funcional y que pueda servir de base para 
                otros futuros proyectos.
            </p>
            <br>

            <h2>Reconocimiento</h2>

            <h3>Paso 1:</h3>

            <p>
                Antes de empezar con nuestro Crawler, primero tenemos que escoger la p치gina objetivo. Yo us칠 la p치gina de [Real Python](https://realpython.com), usando el siguiente 
                link: <a href="https://realpython.github.io/fake-jobs/">https://realpython.github.io/fake-jobs/</a>
            </p>

            <p>
                En este ejemplo us칠 esta p치gina ya que a como se muestra en los entrenamientos de <a href="https://realpython.com">Real Python</a>, esta es la mejor forma de aprender ya que la 
                p치gina es 100% est치tica por lo que no va a haber ning칰n cambio futuro que afecte el desempe침o del Crawler.
            </p>
<br>
<br>
            <h3>Paso 2:</h3>
            <p>
                Una vez dentro se debe de identificar la informaci칩n en la cual estamos interesados:
            </p>
            <br>
            <img src="../assets/img/p2.png" alt="Foto paso 2">
<br>
<br>
            <h3>Paso 3:</h3>

            <p>
                Cuando ya tenemos nuestros objetivos identificados, se procede a buscarlos en el HTML haciendo uso de la secuencia de teclas <strong>CTRL + SHIFT + I</strong>.
            </p>
<br>
<br>
            <h3>Paso 4:</h3>

            <p>
                Explorando las Herramientas para el Desarrollador podemos notar que la informaci칩n que necesitamos se encuentra en las etiquetas de encabezado <em>&lt;h2&gt;, &lt;h3&gt; y &lt;p&gt;.</em>
            </p>
            <br>
                <img src="../assets/img/p3.png" alt="Foto pas 4">
            
            <p></p>
<br>
<br>
            <h2>游빍Desarrollo</h2>

            <h3>Paso 1:</h3>
            <p>
                Primero, se deben de importar las paqueter칤as esenciales para este proyecto:
            </p>
            <br>
            <pre><code class="language-python">

                pip install requests beautifulsoup4
                ...

            </code></pre>
<br>
<br>
            <h3>Paso 2:</h3>

            <p>
            Una vez importadas las bibliotecas necesarias, se procede a trabajar en el c칩digo: 
            </p>
<br>
            <pre><code class="language-python">

                python:

                import requests
                from bs4 import BeautifulSoup

            </code></pre>
<br>
            <p>
                Despu칠s de importar los m칩dulos, lo primero que se debe hacer es definir la `URL` de la p치gina que se va 
                a analizar. Luego, se realiza una solicitud `HTTP` a la p치gina web y se almacena su contenido en una variable.
            </p>
<br>
            <pre><code class="language-python">

                python:

                URL = "https://realpython.github.io/fake-jobs/"
                page = requests.get(URL)

            </code></pre>
<br>
<br>
            <h3>Paso 3:</h3>
            <p>
                Se crea un objeto "BeautifulSoup" para analizar el contenido "HTML" de la p치gina. A continuaci칩n, se busca el elemento en la p치gina con el ID <strong>ResultsContainer</strong>.
            </p>
<br>
            <pre><code class="language-python">

                python:

                soup = BeautifulSoup(page.content, "html.parser")
                results = soup.find(id="ResultsContainer")

            </code></pre>
<br>
<br>
            <h3>Paso 4:</h3>

            <p>
            En este caso, el crawler consulta al usuario sobre el puesto de trabajo en el que est치 interesado. Se crea la variable "tema" para realizar esta consulta y luego la variable "minus" 
            convierte el tema ingresado a min칰sculas para una comparaci칩n que no distingue entre may칰sculas y min칰sculas:  
            </p>
<br>
            <pre><code class="language-python">

                python:

                tema = input("En cu치l trabajo se encuentra interesado?:  ")
                minus = tema.lower()

            </code></pre>
<br>
<br>
            <h3>Paso 5:</h3>
            <p>
                Ahora indicamos al programa que debe encontrar todos los elementos &lt;h2&gt; que contienen el "tema" ingresado, junto con sus elementos padres:
            </p>
<br>
            <pre><code class="language-python">

                python:

                Request_jobs = results.find_all("h2", string=lambda text: minus in text.lower())
                Request_job_elements = [h2_element.parent.parent.parent for h2_element in Request_jobs]

            </code></pre>
<br>
            <p>
                En caso de que desee que el programa busque los resultados de forma predeterminada en lugar de ingresarlos manualmente, simplemente debe <strong>comentar</strong> 
                las variables "tema" y "minus". Luego, en la l칤nea de "Request_jobs", cambie `minus` por el t칠rmino que desee que el programa busque. Por ejemplo:
            </p>
<br>
            <pre><code class="language-python">

                python:

                Request_jobs = results.find_all("h2", string=lambda text: "energy" in text.lower())

            </code></pre>
<br>
            <p>
                <strong>Nota:</strong> El valor agregado debe de ser escrito simpre en min칰scula.
            </p>
<br>
<br>
            <h3>Paso 6:</h3>

            <p>
            Finalmente, vamos a iterar sobre los elementos de trabajo encontrados y mostrar la informaci칩n relevante 
            </p>
<br>
            <pre><code class="language-python">

                python:

                for job_element in Request_job_elements:
                    title_element = job_element.find("h2", class_="title")
                    company_element = job_element.find("h3", class_="company")
                    location_element = job_element.find("p", class_="location")
                    print(title_element.text.strip())
                    print(company_element.text.strip())
                    print(location_element.text.strip())
                    link_url = job_element.find_all("a")[1]["href"]
                    print(f"Apply here: {link_url}\n")
                    print()

            </code></pre>
<br>
            <p>
                <strong>Nota:</strong> La l칤nea "link_url = job_element.find_all("a")[1]["href"]"" se encarga de obtener el enlace del trabajo, lo que nos permite aplicar al trabajo en caso de que lo deseemos.
            </p>
            <br>
            <br>
            <h2>Conclusi칩n:</h2>

            <p>
                Para finalizar con este c칩digo vamos a agrgegarlas cosas est칠ticas para darle un poco m치s de cuerpo al programa.
            </p>

            <p>
                En este caso, he agregado una variable llamada "titulo" que se encargar치 de imprimir los trabajos en los que estoy interesado. Adem치s, en el comando "print", he a침adido separadores <strong>'-'</strong> para 
                que el t칤tulo parezca estar subrayado y se ajuste a lo largo de nuestro t칤tulo dependiendo del n칰mero de caracteres:
            </p>
<br>
            <pre><code class="language-python">

                python:

                titulo = "Trabajos en " + tema
                print("\n" + titulo + "\n" + "-" * len(titulo) + "\n")

            </code></pre>
<br>
            <p>
                <strong>Nota:</strong> Recuerde que si ha comentado la variable "tema" para ejecutar una b칰squeda de trabajos predeterminada, tambi칠n debe hacer el cambio en la variable "titulo" y colocar los trabajos 
                predeterminados seleccionados para que no afecte a la est칠tica.
            </p>

            <p>
                Por 칰ltimo, me gust칩 la idea de agregar un comando "print" que me muestre cu치ntos trabajos relacionados a la b칰squeda ha encontrado:
            </p>
            <br>

            <pre><code class="language-python">

                python:

                print("[*] B칰squedas relacionadas " + str(len(Request_jobs)) + "\n")python

                print("[*] B칰squedas relacionadas " + str(len(Request_jobs)) + "\n")

            </code></pre>
<br>
            <h2>C칩digo final</h2>

            <pre><code class="language-python">

                python:

                import requests
                from bs4 import BeautifulSoup


                URL = "https://realpython.github.io/fake-jobs/"
                page = requests.get(URL)

                soup = BeautifulSoup(page.content, "html.parser")
                results = soup.find(id="ResultsContainer")

                tema = input("En cual trabajo se enceuntra interesado?:  ")
                titulo = "Trabajos en " + tema
                minus = tema.lower()

                print("\n" + titulo + "\n" + "-" * len(titulo) + "\n")
                Request_jobs = results.find_all(
                    "h2", string=lambda text: minus in text.lower()
                )
                Request_job_elements = [
                    h2_element.parent.parent.parent for h2_element in Request_jobs
                ]

                print("[*] B칰squedas relacionadas " + str(len(Request_jobs)) + "\n")
                for job_element in Request_job_elements:
                    title_element = job_element.find("h2", class_="title")
                    company_element = job_element.find("h3", class_="company")
                    location_element = job_element.find("p", class_="location")
                    print(title_element.text.strip())
                    print(company_element.text.strip())
                    print(location_element.text.strip())
                    link_url = job_element.find_all("a")[1]["href"]
                    print(f"Apply here: {link_url}\n")
                    print()

            </code></pre>
            <br>
            <h3>游 Resultado del programa</h3>

            <img src="/assets/img/re.png" alt="Resultado Final">
<br>
            <h2>C칩digo Documentado</h2>

            <pre><code class="language-python">

                #!/usr/bin/python3

                # Importaci칩n de m칩dulos necesarios
                import requests
                from bs4 import BeautifulSoup

                # Definici칩n de la URL de la p치gina web a analizar
                URL = "https://realpython.github.io/fake-jobs/"

                # Realizar una solicitud HTTP a la p치gina web y almacenar el contenido de la p치gina en una variable
                page = requests.get(URL)

                # Crear un objeto BeautifulSoup para analizar el contenido HTML de la p치gina
                soup = BeautifulSoup(page.content, "html.parser")

                # Encontrar el elemento en la p치gina con el ID "ResultsContainer"
                results = soup.find(id="ResultsContainer")

                # Solicitar al usuario que ingrese el tema de trabajo de inter칠s
                tema = input("En cu치l trabajo se encuentra interesado?:  ")

                # Construir el t칤tulo para mostrar en la salida
                titulo = "Trabajos en " + tema

                # Convertir el tema ingresado a min칰sculas para una comparaci칩n insensible a may칰sculas y min칰sculas
                minus = tema.lower()

                # Imprimir el t칤tulo con l칤neas separadoras
                print("\n" + titulo + "\n" + "-" * len(titulo) + "\n")

                # Encontrar todos los elementos &lt;h2&gt; que contienen el tema ingresado y sus elementos padres
                Request_jobs = results.find_all("h2", string=lambda text: minus in text.lower())
                Request_job_elements = [h2_element.parent.parent.parent for h2_element in Request_jobs]

                # Imprimir el n칰mero de trabajos relacionados encontrados
                print("[*] B칰squedas relacionadas " + str(len(Request_jobs)) + "\n")

                # Iterar sobre los elementos de trabajo encontrados y mostrar la informaci칩n relevante
                for job_element in Request_job_elements:
                    title_element = job_element.find("h2", class_="title")
                    company_element = job_element.find("h3", class_="company")
                    location_element = job_element.find("p", class_="location")
                    print(title_element.text.strip())
                    print(company_element.text.strip())
                    print(location_element.text.strip())
                    
                    # Obtener el enlace para aplicar al trabajo
                    link_url = job_element.find_all("a")[1]["href"]
                    print(f"Apply here: {link_url}\n")
                    print()

            </code></pre>
<br>
<br>
            <p>游빌 Este c칩digo realiza lo siguiente:</p>

            <ul>
                <li>Realiza una solicitud HTTP a una p치gina web.</li>
                <li>Utiliza BeautifulSoup para analizar el contenido HTML de la p치gina.</li>
                <li>Encuentra elementos espec칤ficos en la p치gina web.</li>
                <li>Interact칰a con el usuario para obtener informaci칩n sobre el trabajo de inter칠s.</li>
                <li>Filtra los trabajos que coinciden con el tema de inter칠s.</li>
                <li>Muestra informaci칩n relevante sobre los trabajos encontrados, incluidos t칤tulos, empresas, ubicaciones y enlaces para aplicar.</li>
            </ul>
            <br>
            <p>
                Este proyecto fue una excelente forma de aplicar conocimientos pr치cticos sobre scraping y procesamiento de datos web. El enfoque modular y controlado sobre una p치gina est치tica lo hace ideal como punto de partida para proyectos m치s avanzados en ciberinteligencia.
            </p>
      </article>
      </div>
    </section>
  </main>
</body>
</html>
